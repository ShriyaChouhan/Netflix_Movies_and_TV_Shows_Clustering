{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "0wOQAZs5pc--",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "BZR9WyysphqO",
        "YJ55k-q6phqO",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "RcRpF_Kh2vBO",
        "goC072C75nCn",
        "S5rmRUF_5r_U",
        "0gxMQ-AzLYTm",
        "v8amQ_8Way0K",
        "9phdRGXeetzp",
        "NC_X3p0fY2L0",
        "q29F0dvdveiT",
        "g-ATYxFrGrvw",
        "I79__PHVH19G",
        "Nff-vKELpZyI",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "89xtkJwZ18nB",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShriyaChouhan/Netflix_Movies_and_TV_Shows_Clustering/blob/main/Netflix_Movies_and_TV_shows_clusteringipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Netflix Movies and TV Shows Clustering***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Unsupervised\n",
        "##### **Name** :- Shriya Chouhan\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Project Summary: Unveiling Viewer Preferences through Clustering Analysis of Netflix Content**\n",
        "\n",
        "In this project, we delve into the realm of Netflix movies and TV shows by conducting a comprehensive clustering analysis. The dataset, named \"NETFLIX MOVIES AND TV SHOWS CLUSTERING.CSV,\" encompasses a wide array of details about the content available on the Netflix platform. The primary objective of this undertaking is to unravel underlying patterns in viewer preferences, allowing us to discern distinct content categories and enhance content recommendation systems.\n",
        "\n",
        "### **Dataset Overview:**\n",
        "The dataset provides a wealth of information for each movie and TV show, ranging from title, release year, genre, duration, to other pertinent attributes. These attributes offer a holistic view of Netflix's content library, serving as the foundation for our clustering analysis.\n",
        "### **Methodology:**\n",
        "1. **Data Exploration and Cleaning:--** Commence by loading and examining the CSV file, followed by thorough data cleaning. Tasks involve handling missing values, encoding categorical features (e.g., genre), and potentially transforming or normalizing numerical features.\n",
        "2. **Feature Selection:--**  Tailor the dataset to include relevant features conducive to clustering analysis. Factors like genre, release year, and duration could significantly influence content categorization.\n",
        "3. **Clustering Algorithm Selection:--** Opt for appropriate clustering algorithms aligned with the dataset's characteristics and project goals. Options encompass K-Means, Hierarchical Clustering, and Density-Based Spatial Clustering of Applications with Noise (DBSCAN).\n",
        "4. **Dimensionality Reduction (if applicable):--**  If the dataset is high-dimensional, employ techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) to condense the data for easier visualization and clustering.\n",
        "5. **Clustering Analysis:--** Apply chosen clustering algorithms to the dataset. Analyze the resulting clusters in terms of composition, distribution, and notable attributes.\n",
        "6. **Cluster Visualization:--** Utilize dimensionality reduction outcomes to create visualizations that portray the clusters' spatial relationships, aiding in understanding content groupings.\n",
        "7. **Interpreting Clusters:--** For each cluster, dissect the characteristics of the movies and TV shows within. Uncover shared traits, prevalent genres, and potential viewer preferences encapsulated within each cluster.\n",
        "8. **Evaluation (if applicable):--** If ground truth labels are available (e.g., genre labels), employ metrics like Adjusted Rand Index or Normalized Mutual Information to assess clustering quality.\n",
        "\n",
        "###**Project Deliverables:**\n",
        "1. **Exploratory Data Analysis (EDA):--** Offer insights into data statistics, distributions, and visualizations to provide a preliminary grasp of content attributes.\n",
        "2. **Clustering Analysis Results:--** Present outcomes of the clustering analysis, outlining cluster distribution, characteristics, and key attributes.\n",
        "3. **Visualizations:--** Showcase visual representations of clusters, enabling intuitive understanding of content groupings.\n",
        "4. **Insights and Interpretations:--** Share profound insights drawn from cluster analysis, potentially revealing interesting content groupings or genre associations.\n",
        "\n",
        "### Conclusion:--\n",
        "By conducting a thorough clustering analysis on the Netflix movies and TV shows dataset, this project aims to illuminate latent patterns in viewer preferences. The insights gleaned from this endeavor have the potential to bolster content recommendation algorithms, enrich user experience, and shed light on the intricate landscape of content categorization on the Netflix platform.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ShriyaChouhan/Netflix_Movies_and_TV_Shows_Clustering"
      ],
      "metadata": {
        "id": "ma0aO6jljUDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Problem Statement: Uncovering Content Patterns through Clustering Analysis of Netflix Movies and TV Shows***\n",
        "In the era of digital streaming, Netflix hosts an extensive library of movies and TV shows, catering to a diverse global audience. However, the challenge lies in efficiently organizing this immense collection to deliver personalized recommendations and enhance user satisfaction. The problem at hand is to perform a comprehensive clustering analysis on the dataset named \"NETFLIX MOVIES AND TV SHOWS CLUSTERING.CSV,\" aiming to reveal latent content patterns, genre associations, and viewer preferences. The ultimate goal is to provide actionable insights that can optimize content categorization and enhance the overall user experience on the Netflix platform.\n",
        "**Key Challenges:--**\n",
        "1. **Content Diversity:--** The dataset covers a wide range of genres, languages, and release years, making it intricate to discern coherent content clusters solely based on attributes like genre or duration.\n",
        "2. **Feature Selection:--** Determining the most influential attributes for clustering is crucial. Choosing whether to incorporate variables such as cast, directors, or language while managing computational complexity poses a challenge.\n",
        "\n",
        "3. **Dimensionality:--** High-dimensional data can hinder effective clustering analysis. Selecting appropriate dimensionality reduction techniques to capture essential information while reducing noise requires careful consideration.\n",
        "\n",
        "4. **Cluster Interpretation:--** Forming clusters is only the first step. Unveiling the underlying characteristics of these clusters in terms of prevalent genres, content themes, and viewer preferences requires insightful analysis.\n",
        "\n",
        "5.**Algorithm Selection:--** Choosing the right clustering algorithms that capture the intrinsic structure of the data and result in meaningful clusters is a critical decision.\n",
        "\n",
        "6. **Evaluation:--** In the absence of predefined labels, assessing the quality of clusters poses a challenge. Selecting suitable evaluation metrics to measure clustering effectiveness and coherence is essential.\n",
        "\n",
        "### ***Objectives:--***\n",
        "This project aims to achieve the following objectives:--\n",
        "\n",
        "1. **Data Preprocessing:--** Rigorously clean and preprocess the \"NETFLIX MOVIES AND TV SHOWS CLUSTERING.CSV\" dataset, addressing missing data, encoding categorical variables, and transforming numerical features.\n",
        "\n",
        "2. **Clustering Analysis:--** Apply advanced clustering algorithms, such as Gaussian Mixture Models (GMM) or Agglomerative Hierarchical Clustering, to unveil latent content patterns and relationships.\n",
        "\n",
        "3. **Dimensionality Reduction:--** Employ dimensionality reduction techniques like Linear Discriminant Analysis (LDA) or Autoencoders to transform high-dimensional data into a more manageable format while retaining key information.\n",
        "\n",
        "4. **Cluster Interpretation:--** Thoroughly interpret the formed clusters, identifying prevalent genres, recurring content themes, and potential viewer preferences within each cluster.\n",
        "\n",
        "5.**Insights Generation:--** Extract actionable insights from the clustering outcomes that can directly influence content recommendation strategies, content categorization, and user engagement enhancement.\n",
        "\n",
        "6. **Documentation and Presentation:--** Provide clear documentation of the analysis pipeline, from data preprocessing to clustering algorithms used, visualization methods, insights gained, and potential applications.\n",
        "\n",
        "### ***Expected Outcomes:--***\n",
        "The successful completion of this project is anticipated to yield the following outcomes:\n",
        "\n",
        "1. Well-defined clusters of Netflix movies and TV shows that encapsulate content relationships and viewer preferences.\n",
        "2. Visual representations of clusters, aiding in comprehending content distributions and potential trends across clusters.\n",
        "3. In-depth insights into genre associations, content theme dynamics, and potential cross-genre viewer preferences.\n",
        "4. Recommendations for refining content recommendation algorithms, contributing to improved user satisfaction and engagement on the Netflix platform.\n",
        "### ***Impact:---***\n",
        "The results of this project have the potential to revolutionize content organization and recommendation on the Netflix platform. By gaining a deeper understanding of content patterns and viewer preferences through clustering analysis, Netflix can enhance its recommendation algorithms, leading to increased user engagement, satisfaction, and potentially broadening its viewer base."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Import Libraries for Data Manipulation and Visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import missingno as msno\n",
        "import matplotlib.cm as cm\n",
        "import geopandas as gpd\n",
        "!pip install country_converter --upgrade\n",
        "import country_converter as coco\n",
        "import plotly.express as px\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import string for Removing Punctuations\n",
        "import string\n",
        "# import re for Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "# import nltk and corpus for remove Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# remove phrase text\n",
        "import random\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Import Warnings Module to Suppress Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path =  \"/content/drive/MyDrive/AlmaBetter/Capstone Projects/Netflix_Movies_and_TV_shows_clustering/\"\n",
        "netflix_dataset = pd.read_csv(path + \"NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv\")"
      ],
      "metadata": {
        "id": "Oa15MOq-uMmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "netflix_dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset last look\n",
        "netflix_dataset.tail()"
      ],
      "metadata": {
        "id": "GhE9Z50awNgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Netflix Dataset Rows & Columns count\n",
        "# Count the number of rows\n",
        "rows = len(netflix_dataset.index)\n",
        "\n",
        "# Count the  number of columns\n",
        "columns = len(netflix_dataset.columns)\n",
        "\n",
        "# Print the number of rows and columns\n",
        "print(\"The number of  rows is:\", rows)\n",
        "print(\"The number of  columns is:\", columns)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Netflix Dataset Info\n",
        "load_data_info = netflix_dataset.info()\n",
        "print(load_data_info)"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Netflix Dataset Duplicate Value Count\n",
        "# Count the number of duplicate rows\n",
        "duplicate_rows = netflix_dataset[netflix_dataset.duplicated()]\n",
        "\n",
        "# Count the number of duplicate values\n",
        "num_of_duplicate_values = len(duplicate_rows)\n",
        "\n",
        "# Print the number of duplicate values\n",
        "print(\"Number of duplicate values is:\", num_of_duplicate_values)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values  = netflix_dataset.isnull().sum()\n",
        "\n",
        "# Print the missing values\n",
        "print(\"The number of missing values is:\", missing_values)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Create a bar plot to  visualize the missing values\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=missing_values.index, y = missing_values.values)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Missing Values in Netflix Dataset\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.ylabel(\"Number of missing values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some things I know about the Netflix movies and TV shows dataset are:--**\n",
        "\n",
        "\n",
        "1. The dataset contains information about 10,000(approx) movies and TV shows that are available on Netflix.\n",
        "2. The dataset includes the following features:--\n",
        "*  Show ID\n",
        "*  Type (Movei or TV show)\n",
        "*  Title\n",
        "*  Director\n",
        "*  Cast\n",
        "*  Country\n",
        "*  Date added\n",
        "*  Release year\n",
        "*  Rating\n",
        "*  Duration\n",
        "*  Listed_in\n",
        "*  Description\n",
        "\n",
        "3. There are 7 missing values in the rating column.\n",
        "\n",
        "\n",
        "I learned these things by loading the dataset into a Pandas DataFrame and inspecting the data. I also used matplotlib to visualize the missing values in the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "columns_name = netflix_dataset.columns\n",
        "\n",
        "# Print the dataset  information\n",
        "print(\"Column names:\\n\", columns_name)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the netflix dataset describe\n",
        "netflix_dataset.describe()"
      ],
      "metadata": {
        "id": "uYykf8_ysLS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall discriprion of netflix dataset\n",
        "netflix_dataset.describe(include='all').transpose()\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***The description of the variables in the Netflix movies and TV shows clustering dataset:--***\n",
        "\n",
        "* **show_id:--** A unique identifier for each movie or TV show. It is an object value.\n",
        "* **type:--** This column indicates whether the movie or TV show is a movie or a TV show. It is an object value with two possible values: **\"movie\"** or **\"tv show\"**.\n",
        "* **title:--** This column is the title of the movie or TV show. It is an object value.\n",
        "* **director:--** This column is the director of the movie or TV show. It is an object value.\n",
        "* **cast:--** This column is the main actors in the movie or TV show. It is an object value.\n",
        "* **country:--** This column is the country where the movie or TV show was produced. It is an object value.\n",
        "* **date_added:--** This column is the date the movie or TV show was added to Netflix. It is an object value in the format YYYY-MM-DD.\n",
        "* **release_year:--** This column is the year the movie or TV show was released. It is an integer value.\n",
        "* **rating:--** This column is the rating of the movie or TV show on Netflix. It is an object value.\n",
        "* **duration:--** This column is the duration of the movie or TV show in minutes. It is an object value.\n",
        "* **listed_in:--** This column is the genres of the movie or TV show. It is an object value with multiple possible values, separated by commas.\n",
        "* **description:--** This column is the description of the movie or TV show. It is an object value.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Unique values for each variable\n",
        "for i in netflix_dataset.columns.tolist():\n",
        "  print(f'Number of unique value in {i} is {netflix_dataset[i].nunique()}.')"
      ],
      "metadata": {
        "id": "AsYIGJq3vdAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in netflix_dataset.columns:\n",
        "  print(\"Variables:\", column)\n",
        "  print(\"Unique Values:\", netflix_dataset[column].unique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_dataset[['director','country']] = netflix_dataset[['director','country']].fillna('Unknown')\n",
        "netflix_dataset['cast'] = netflix_dataset['cast'].fillna('No Cast')\n",
        "netflix_dataset['rating'] = netflix_dataset['rating'].fillna(netflix_dataset['rating'].mode()[0])\n",
        "netflix_dataset.dropna(axis=0, inplace = True)"
      ],
      "metadata": {
        "id": "r0fcu69OIuUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for missing values\n",
        "netflix_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "9K_HChzgJuAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Typecasting 'date_added' from string to datetime\n",
        "netflix_dataset[\"date_added\"] = pd.to_datetime(netflix_dataset['date_added'])\n",
        "\n",
        "# Adding new attributes month and year of date added\n",
        "netflix_dataset['month_added'] = netflix_dataset['date_added'].dt.month\n",
        "netflix_dataset['year_added'] = netflix_dataset['date_added'].dt.year\n",
        "netflix_dataset.drop('date_added', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "7bgBzwopJ1BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##check for duplicates\n",
        "duplicates =len(netflix_dataset[netflix_dataset.duplicated()])\n",
        "print(duplicates)"
      ],
      "metadata": {
        "id": "UXaOLg0vKah7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Univariate Analysis***"
      ],
      "metadata": {
        "id": "9hcrDeoZN2-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 --- What is the distribution of release years in the dataset?"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# Plot the distribution of release years\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(netflix_dataset['release_year'], bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Release Years in Netflix Dataset')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a histogram chart because it's suitable for visualizing the distribution of discrete data, like release years. It helps identify trends, patterns, and frequencies in the distribution of years."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the distribution of release years in the chart could include spotting content production trends, identifying historical patterns in popularity, observing shifts in content types, and gauging the growth and longevity of the platform."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***Positive Business Impact:---***\n",
        "Insights can positively impact content strategy, resource allocation, customer retention, and strategic partnerships.\n",
        "\n",
        "\n",
        " ***Negative Growth and Challenges:---***\n",
        "Discontinuing older content, overemphasizing trends, neglecting niche audiences, and ignoring platform growth could lead to negative outcomes like customer churn and missed opportunities.\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 --- What is the distribution of content addition dates(month_added, year_added) for movies and TV shows?"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Filter data for movies and TV shows\n",
        "Movies = netflix_dataset[netflix_dataset['type'] == 'Movie']\n",
        "TV_Shows = netflix_dataset[netflix_dataset['type'] == 'TV Show']"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot overlapping histograms for content addition dates(Month added)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(Movies['month_added'], bins=30, color='blue', alpha=0.5,label='Movies', edgecolor='black')\n",
        "plt.hist(TV_Shows['month_added'], bins=30, color='red', alpha=0.5, label='TV Shows', edgecolor='black')\n",
        "plt.title('Distribution of Content Addition(Month) Dates for Movies and TV Shows')\n",
        "plt.xlabel('Month Added')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6TPzwKoBQDx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot overlapping histograms for content addition dates(Year added)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(Movies['year_added'], bins=30, color='green', alpha=0.5,label='Movies', edgecolor='black')\n",
        "plt.hist(TV_Shows['year_added'], bins=30, color='red', alpha=0.5, label='TV Shows', edgecolor='black')\n",
        "plt.title('Distribution of Content Addition(Year) Dates for Movies and TV Shows')\n",
        "plt.xlabel('Year Added')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Er_M5T-yRElF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose overlapping histograms to compare the distribution of content addition dates for movies and TV shows because it allows us to visualize how the date distributions of the two types overlap, helping us understand any patterns or differences in their release over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the chart could include identifying release patterns, observing a balanced addition of content types, understanding platform strategies, recognizing date disparities between content types, and evaluating content diversity throughout different timeframes."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can lead to strategic content releases, balanced content library, catering to viewer preferences, and maintaining content diversity.\n",
        "\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "Date disparities and content imbalance could lead to viewer dissatisfaction, overemphasis on trends might cause short-lived popularity, and uniform content distribution might result in viewer month_added and year_added"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 --- Is there a correlation between content duration and release year?"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "\n",
        "# Create a line plot with multiple lines\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='release_year', y='duration', hue='type', data=netflix_dataset)\n",
        "plt.title('Content Duration Trend by Release Year and Type')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Mean Content Duration')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I choose the line plot with multiple lines because it effectively shows the trend of content duration for both movie and TV show types over different release years. It allows for easy comparison and identification of patterns in duration changes for each type, making it suitable for visualizing the relationship between these variables.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights might include consistency or divergence in content duration trends, changing viewer preferences, potential platform strategies, the influence of release year, and stability in content production approaches."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can inform strategy, optimize planning, enhance content diversity, and improve retention strategies.\n",
        "\n",
        "***Negative Growth and Challenges:--***\n",
        "Diverging content strategies may lead to audience fragmentation, ignoring trends could result in churn, resource imbalance might occur, and short-term focus may affect long-term engagement."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 --- How does the average content duration vary across different ratings?"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Convert content duration to numerical values (in minutes)\n",
        "netflix_dataset['duration'] = netflix_dataset['duration'].str.extract('(\\d+)').astype(float)\n",
        "\n",
        "# Group data by rating and calculate the mean duration\n",
        "grouped_data = netflix_dataset.groupby('rating')['duration'].mean().reset_index()\n",
        "\n",
        "# Sort ratings based on average duration\n",
        "grouped_data = grouped_data.sort_values(by='duration', ascending=False)\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(grouped_data['rating'], grouped_data['duration'], color='skyblue')\n",
        "plt.title('Average Content Duration Across Different Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Average Content Duration (minutes)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I chose a bar plot because it effectively compares the average content duration across different ratings, making it easy to identify variations and trends."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Insights from the chart might include understanding how content duration varies across different ratings, identifying whether certain content ratings tend to have longer or shorter durations, and helping Netflix tailor its content production strategies based on viewer preferences."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can help optimize content production strategies, aligning content duration with viewer preferences for improved engagement and satisfaction.\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "Extreme variations in content duration might lead to viewer dissatisfaction, impacting engagement and potentially causing churn, especially if content durations do not match viewers' expectations for specific ratings."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 --- What is the average content duration for different listed_in?"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Sort by average duration in descending order and get the top 10 categories\n",
        "top_10_categories = grouped_data.nlargest(10, 'duration')\n",
        "\n",
        "# Create a bar plot for the top 10 categories\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(top_10_categories.index, top_10_categories['duration'], color='skyblue')\n",
        "plt.title('Top 10 Categories by Average Content Duration')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Average Content Duration (minutes)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I suggested a bar plot because it's commonly used to compare categories, making it suitable for showing average content duration differences among the top 10 categories. It's an effective way to visualize such data. If you have different visualization goals or specific data characteristics, other chart types might be more appropriate."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The insights from the chart could include identifying categories with the longest average content duration, understanding viewer preferences, recognizing potentially popular content areas, and making informed content strategy decisions based on viewer engagement."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can lead to strategic content planning, optimizing content duration for categories that attract more viewers, enhancing user engagement, and improving user satisfaction.\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "Extreme variations in content duration across categories might lead to viewer dissatisfaction, as inconsistent durations within a category could fail to meet viewer expectations."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Bivariate Analysis (Numerical - Categorical)***"
      ],
      "metadata": {
        "id": "1xQS8BUFedNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 ---  How does the average duration vary between movies and TV shows?"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Group data by 'type' and calculate the mean duration\n",
        "grouped_data = netflix_dataset.groupby('type')['duration'].mean().reset_index()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(grouped_data['type'], grouped_data['duration'], color='orange')\n",
        "plt.title('Average Content Duration: Movies vs TV Shows')\n",
        "plt.xlabel('Content Type')\n",
        "plt.ylabel('Average Content Duration (minutes)')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar plot because it effectively compares the average content duration between movies and TV shows, allowing for a clear visual comparison of the durations for each content type."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights might include understanding whether movies or TV shows tend to have longer content durations on average and whether there are significant differences in duration between the two types. This information can guide content production decisions based on viewer preferences and expectations."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can guide content strategy, aligning content duration with viewer preferences for each type, potentially increasing viewer engagement and satisfaction.\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "If content durations for movies or TV shows significantly deviate from viewer expectations, it might lead to dissatisfaction as viewers might be disappointed with content that is shorter or longer than what they anticipate."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 --- What is the distribution of content addition dates for movies and TV shows?"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Convert 'date_added' column to datetime\n",
        "netflix_dataset['month_added'] = pd.to_datetime(netflix_dataset['month_added'])\n",
        "\n",
        "# Separate data for movies and TV shows\n",
        "movies_data = netflix_dataset[netflix_dataset['type'] == 'Movie']\n",
        "tv_shows_data = netflix_dataset[netflix_dataset['type'] == 'TV Show']\n",
        "\n",
        "# Create KDE plots\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# KDE plot for movie addition dates\n",
        "sns.kdeplot(movies_data['month_added'], label='Movies')\n",
        "\n",
        "# KDE plot for TV show addition dates\n",
        "sns.kdeplot(tv_shows_data['month_added'], label='TV Shows')\n",
        "\n",
        "plt.title('Distribution of Content Addition Dates for Movies and TV Shows')\n",
        "plt.xlabel('Month Added')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date_added' column to datetime\n",
        "netflix_dataset['year_added'] = pd.to_datetime(netflix_dataset['year_added'])\n",
        "\n",
        "# Separate data for movies and TV shows\n",
        "movies_data = netflix_dataset[netflix_dataset['type'] == 'Movie']\n",
        "tv_shows_data = netflix_dataset[netflix_dataset['type'] == 'TV Show']\n",
        "\n",
        "# Create KDE plots\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# KDE plot for movie addition dates\n",
        "sns.kdeplot(movies_data['year_added'], label='Movies')\n",
        "\n",
        "# KDE plot for TV show addition dates\n",
        "sns.kdeplot(tv_shows_data['year_added'], label='TV Shows')\n",
        "\n",
        "plt.title('Distribution of Content Addition Dates for Movies and TV Shows')\n",
        "plt.xlabel('Year Added')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rw-_uhC4gsjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose KDE (Kernel Density Estimation) plots to visualize the distribution of content addition dates for movies and TV shows because they provide a smooth representation of data density, allowing us to observe the patterns and variations in the distribution over time."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Insights might include identifying the months or years when content addition is more frequent for movies and TV shows, potentially indicating patterns of content release or acquisition by Netflix."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can guide content release schedules, ensuring strategic timing for content additions to match viewer preferences and optimize engagement.\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "If the distribution shows irregular or sparse content addition, it might lead to viewer dissatisfaction due to inconsistent updates. This could potentially result in reduced engagement or even churn."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 --- Is there a correlation between content duration and release year?"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='release_year', y='duration', data=netflix_dataset, alpha=0.5)\n",
        "plt.title('Content Duration vs Release Year')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Content Duration (minutes)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a scatter plot because it effectively displays the relationship between two numerical variables, in this case, content duration and release year. It allows for visualizing potential trends, patterns, and variations between these two variables."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Insights might include identifying trends or patterns in content duration over different release years, potentially indicating changes in content production preferences or strategies over time."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can guide content planning and production, aligning content duration with viewer preferences over different release years, potentially enhancing viewer engagement and satisfaction.\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "If the scatter plot shows a negative trend or irregular distribution, it might indicate viewer dissatisfaction with content duration over time, potentially leading to reduced engagement and viewer churn."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 ---  How does the average content duration vary across different ratings?"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Group data by 'rating' and calculate the mean duration\n",
        "grouped_data = netflix_dataset.groupby('rating')['duration'].mean().reset_index()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='rating', y='duration', data=grouped_data, palette='pastel')\n",
        "plt.title('Average Content Duration Across Different Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Average Content Duration (minutes)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar plot because it effectively displays the average content duration for different ratings, allowing for easy comparison and identification of differences in content duration across rating categories."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights might include identifying whether content duration varies significantly across different ratings, potentially indicating content strategy preferences based on viewer rating or duration."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can aid in tailoring content duration to align with viewer preferences for specific rating categories, enhancing engagement and viewer satisfaction.\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "If certain rating categories consistently have content durations significantly deviating from viewer expectations, it might lead to viewer dissatisfaction and potential churn, especially if content duration doesn't match the content's intended target audience or genre."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 --- What is the average content duration for different listed_in?\n"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Group data by 'listed_in' and calculate the mean duration\n",
        "grouped_data = netflix_dataset.groupby('listed_in')['duration'].mean().reset_index()\n",
        "\n",
        "# Sort data by average duration\n",
        "grouped_data = grouped_data.sort_values(by='duration', ascending=False)\n",
        "\n",
        "# Select the top 10 categories\n",
        "top_10_categories = grouped_data.head(10)\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='duration', y='listed_in', data=top_10_categories, palette='pastel')\n",
        "plt.title('Top 10 Categories with Highest Average Content Duration')\n",
        "plt.xlabel('Average Content Duration (minutes)')\n",
        "plt.ylabel('Categories')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar plot because it effectively displays and compares the average content duration of the top 10 categories, allowing for easy identification of categories with the highest content duration."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight may include identifying categories that tend to have longer average content duration, potentially reflecting specific content genres or types that prioritize longer storytelling or engagement."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "Insights can guide content strategy by tailoring content duration to align with viewer preferences in specific categories, enhancing viewer engagement and satisfaction.\n",
        "\n",
        "***Negative Growth and Challenges:---***\n",
        "If certain categories consistently have significantly longer content duration without corresponding viewer engagement, it might lead to viewer fatigue or boredom, potentially resulting in reduced viewer retention and negative impact on business."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Bivariate Analysis (Numerical - Numerical)***"
      ],
      "metadata": {
        "id": "XoVUoH7xry_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 ---  Is there a relationship between the release year and content duration?"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.regplot(x='release_year', y='duration', data=netflix_dataset, scatter_kws={'alpha':0.5})\n",
        "plt.title('Content Duration vs Release Year with Regression Line')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Content Duration (minutes)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a scatter plot because it effectively displays the individual data points, allowing for observation of the distribution and any potential patterns or trends between content duration and release year."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights might include identifying whether there is a clear trend or pattern between content duration and release year, potentially indicating changes in content production strategies or viewer preferences over time.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:--***\n",
        "Insights can guide content planning by understanding how content duration preferences have evolved over the years. This can help tailor content strategies to match viewer preferences and optimize engagement.\n",
        "\n",
        "***Negative Growth and Challenges:--***\n",
        "If the insights show a decline in content duration while viewer engagement remains high, it might indicate a shift towards shorter-form content. However, if viewer engagement drops with shorter content, it could lead to negative impact due to reduced viewer satisfaction and retention."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 ---  How does the release year correlate with the number of content items?"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Calculate the number of content items (movies and TV shows) per release year\n",
        "content_count_by_year = netflix_dataset.groupby('release_year')['show_id'].count().reset_index()\n",
        "\n",
        "# Create a line plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x='release_year', y='show_id', data=content_count_by_year)\n",
        "plt.title('Number of Content Items vs Release Year')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Number of Content Items')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XCEcyFTwwbHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the line plot because it effectively shows the trend and relationship between two continuous variables (release year and number of content items) over a continuous range. It helps in visualizing how the number of content items has changed over different release years in a clear and straightforward manner."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line plot shows that the number of content items (movies and TV shows) has generally increased over the years. There was a significant growth in the number of content items around the mid-2010s, suggesting an expansion of Netflix's content library during that period."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight of a growing number of content items over the years can positively impact the business by attracting and retaining subscribers. However, there is no indication of negative growth in this analysis, which is reassuring for business stability."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 --- Is there a correlation between content duration and the year it was added?"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(x='year_added', y='duration', data=netflix_dataset, alpha=0.5)\n",
        "plt.title('Content Duration vs Year Added')\n",
        "plt.xlabel('Year Added')\n",
        "plt.ylabel('Content Duration (minutes)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the scatter plot because it effectively visualizes the relationship between two continuous variables (content duration and year added). It helps in identifying patterns or trends, if any, in how content duration has changed over different years of addition."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot does not indicate a clear and consistent pattern or trend between content duration and the year it was added. Content durations appear to be spread across different years, suggesting no significant correlation between these two variables."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 --- How does the release year correlate with the average content duration?\n"
      ],
      "metadata": {
        "id": "RcRpF_Kh2vBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 14 visualization code\n",
        "# Calculate the average content duration for each release year\n",
        "average_duration_by_year = netflix_dataset.groupby('release_year')['duration'].mean()\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.scatter(average_duration_by_year.index, average_duration_by_year.values, color='red', alpha = 0.5)\n",
        "plt.title(\"Release Year vs Average Content Duration\")\n",
        "plt.xlabel(\"Release Year\")\n",
        "plt.ylabel(\"Average  Content Duration (Minutes)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3jt8F8h24BBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "goC072C75nCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a scatter plot because it's suitable for visualizing the relationship between two continuous variables, in this case, the release year and the average content duration. Scatter plots help in identifying patterns, trends, and potential correlations between variables."
      ],
      "metadata": {
        "id": "NGdNpvt25p8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "S5rmRUF_5r_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot helps us visualize the relationship between release year and average content duration. From the scatter plot, we can observe the following insights:\n",
        "1. ***No Clear Trend:---*** There doesn't seem to be a strong linear trend between release year and average content duration. The points are scattered without a clear pattern.\n",
        "2. ***Variability:---*** The average content duration appears to vary widely across different release years, as indicated by the spread of data points.\n",
        "3. ***Outliers:---*** There are a few outlier points where the average content duration is notably higher or lower than the general trend.\n",
        "4. ***Potential Clusters:---*** There might be clusters of data points around certain release years, suggesting that content duration might have varied more in specific time periods.\n",
        "5. ***Lack of Correlation:---*** The lack of a clear trend suggests that there might not be a strong correlation between release year and average content duration.\n",
        "\n",
        "Overall, the scatter plot doesn't reveal a significant linear correlation between release year and average content duration. The insights suggest that other factors could be influencing content duration more than just the release year."
      ],
      "metadata": {
        "id": "QpdAmjof5xg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "1VPFNWfX6Zid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the scatter plot might not directly lead to a significant positive business impact. The lack of a strong correlation between release year and average content duration suggests that focusing solely on release year as a predictor for content duration may not yield substantial benefits in terms of content strategy or audience engagement.\n",
        "\n",
        "In this case, there are no insights that directly point to negative growth. However, the absence of a meaningful correlation can prevent potential negative outcomes. For instance, if there was a significant negative correlation, it could indicate that older content tends to have longer durations, potentially leading to viewer disinterest. By recognizing that no such correlation exists, the business can avoid making decisions based on a false assumption that could have led to negative consequences.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8zj2cm8o6cx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 -   How does the provided code analyze the release trends of movies and TV shows on Netflix"
      ],
      "metadata": {
        "id": "0gxMQ-AzLYTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 15 visualization code\n",
        "\n",
        "#creating two extra columns\n",
        "tv_shows=netflix_dataset[netflix_dataset['type']=='TV Show']\n",
        "movies=netflix_dataset[netflix_dataset['type']=='Movie']\n"
      ],
      "metadata": {
        "id": "PDBTDM5VLh2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_year =movies['release_year'].value_counts().sort_index(ascending=False)\n",
        "\n",
        "tvshows_year =tv_shows['release_year'].value_counts().sort_index(ascending=False)"
      ],
      "metadata": {
        "id": "3vO_5DhLYiOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysing how many movies released per year in the last 20 years\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(y=movies['release_year'], data=netflix_dataset, order=movies['release_year'].value_counts().index[0:20])\n",
        "plt.title('Number of Movies Released per Year (Last 20 Years)')\n",
        "plt.xlabel('Number of Movies Released')\n",
        "plt.ylabel('Release Year')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "J_HTHFVhYUzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysing how many TV shows released per year in the last 15 years\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(y=tv_shows['release_year'], data=netflix_dataset, order=tv_shows['release_year'].value_counts().index[0:20])\n",
        "plt.title('Number of TV Shows Released per Year (Last 15 Years)')\n",
        "plt.xlabel('Number of TV Shows Released')\n",
        "plt.ylabel('Release Year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EvsigQnZYb7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "vQ0UXnUqY6ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the sns.countplot() chart because it effectively visualizes the distribution of categorical data (release years) and helps compare release counts of movies and TV shows over different time periods. The chart's bars make it easy to spot trends and differences in release frequency, supporting a univariate analysis for understanding content release patterns."
      ],
      "metadata": {
        "id": "B2ZtRojnZBha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "wt0MVBOlZPfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided analysis of content release trends reveals shifts and patterns in movie and TV show releases on Netflix over time. Insights could include identifying peak release years, observing differential patterns between content types, and noting potential changes in content production strategies or audience preferences."
      ],
      "metadata": {
        "id": "XBMs4QVSZTPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "CJVy9m2PZjmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Positive Impact:---*** The gained insights can positively impact Netflix by aiding strategic content planning, data-informed decision-making, and subscriber growth.\n",
        "\n",
        "***Negative Growth:---*** There's a risk of negative impact if insights lead to content oversupply, compromising quality, ignoring viewer preferences, or excessive content costs without corresponding viewership growth."
      ],
      "metadata": {
        "id": "zn7Hg65PZkzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 16 -  Analysing top15 countries with most content"
      ],
      "metadata": {
        "id": "v8amQ_8Way0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Analysing top15 countries with most type\n",
        "plt.figure(figsize=(18,5))\n",
        "sns.countplot(x=netflix_dataset['country'],order=netflix_dataset['country'].value_counts().index[0:15],hue=netflix_dataset['type'])\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('Top 15 countries with most contents', fontsize=15, fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rRoLw3rsaqmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plotting the Horizontal bar plot for top 10 country contains Movie & TV Show split\n",
        "country_order = netflix_dataset['country'].value_counts()[:11].index\n",
        "content_data = netflix_dataset[['type', 'country']].groupby('country')['type'].value_counts().unstack().loc[country_order]\n",
        "content_data['sum'] = content_data.sum(axis=1)\n",
        "content_data_ratio = (content_data.T / content_data['sum']).T[['Movie', 'TV Show']].sort_values(by='Movie',ascending=False)[::-1]\n",
        "\n",
        "# Plotting the barh\n",
        "fig, ax = plt.subplots(1,1,figsize=(15, 8),)\n",
        "\n",
        "ax.barh(content_data_ratio.index, content_data_ratio['Movie'],\n",
        "        color='crimson', alpha=0.8, label='Movie')\n",
        "ax.barh(content_data_ratio.index, content_data_ratio['TV Show'], left=content_data_ratio['Movie'],\n",
        "        color='black', alpha=0.8, label='TV Show')"
      ],
      "metadata": {
        "id": "E0qo1yM7atVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "qZENsz4cbxZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart, a Horizontal Stacked Bar Plot, was chosen because it efficiently compares content types (movies/TV shows) in the top 15 countries. It's suitable for showing the distribution of two variables, color-coded differentiation, and percentage representation, making it easy to interpret and compare content composition."
      ],
      "metadata": {
        "id": "FxCITqmacON2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "dknX5RhBb3Uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The insights from the chart include identifying content type dominance, country-specific preferences, variability across countries, platform strategy implications, opportunities based on trends, and global vs. local content appeal."
      ],
      "metadata": {
        "id": "lfjUh8cCcYnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "EcnBHSkOcBGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Impact:---*** Gained insights can positively impact Netflix by tailoring content strategy, maximizing engagement, penetrating markets, and forming strategic partnerships based on localized preferences.\n",
        "\n",
        "\n",
        "***Negative Impact:---*** Risks include content homogenization, missed trends, overlooking emerging markets, and inefficient resource allocation due to an excessive focus on localized preferences."
      ],
      "metadata": {
        "id": "uTrSOvFacbsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Multivariate Analysis***"
      ],
      "metadata": {
        "id": "G5SmKoC8f2Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 17 - Is there a relationship between content type, release year, and average duration?"
      ],
      "metadata": {
        "id": "9phdRGXeetzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average duration by content type and release year\n",
        "average_duration_by_year = netflix_dataset.groupby(['release_year', 'type'])['duration'].mean().reset_index()\n",
        "\n",
        "# Create a bar plot to analyze the relationship between content type, release year, and average duration\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='release_year', y='duration', hue='type', data=average_duration_by_year)\n",
        "plt.title('Relationship between Content Type, Release Year, and Average Duration')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Average Duration (minutes)')\n",
        "plt.legend(title='Content Type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qZyBQTAEd2xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ILA9zzhNe8Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I chose the bar plot because it effectively displays the relationship between content type, release year, and average duration. It can simultaneously represent continuous (release year) and categorical (content type) data, highlight temporal patterns, and utilize color coding for easy comparison, making it a clear and insightful visualization choice."
      ],
      "metadata": {
        "id": "P7fjK2u4fEQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OYTD9QFTe79X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights from the chart could include changing trends in average content duration over different release years, differences in average duration between movies and TV shows, potential evolution of viewer preferences, impact of specific release years on content duration, implications for platform strategy, and potential connections between content duration and audience engagement."
      ],
      "metadata": {
        "id": "OiVkn-e_fe9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "pMwZWk5Le7zR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Impact:---*** Gained insights can positively impact Netflix by informing content strategy, optimizing viewer experience, and effective resource allocation based on content duration trends.\n",
        "\n",
        "\n",
        "\n",
        "***Negative Impact:---*** Overemphasis on trends might lead to a lack of content variety, stifled creativity, monotonous viewing, and a mismatch between content and changing audience preferences, potentially resulting in negative growth.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zb_PDcBOfn2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 18 - Netflix country wise"
      ],
      "metadata": {
        "id": "H9SNvna1UX4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "country = netflix_dataset.country.value_counts()\n",
        "\n",
        "coun = {}\n",
        "\n",
        "#for loop coutry wise\n",
        "for idx, val in country.items():\n",
        "    l = idx.split(',')\n",
        "    for i in l:\n",
        "        i = i.strip()\n",
        "        if i in coun.keys():\n",
        "            d = {}\n",
        "            d[i] = val + coun[i]\n",
        "            coun.update(d)\n",
        "        else:\n",
        "            d = {i:val}\n",
        "            coun.update(d)\n",
        "\n",
        "nation, count = [],[]\n",
        "for idx, val in coun.items():\n",
        "    nation.append(idx)\n",
        "    count.append(val)\n",
        "\n",
        "#craete a dataframe\n",
        "temp = (pd.DataFrame({'country':nation, 'count': count})\n",
        "        .sort_values('count', ascending = False))\n",
        "\n",
        "\n",
        "temp['color'] = temp['count'].apply(lambda x : '#b20710' if x > temp['count'].values[30] else 'grey')\n",
        "\n",
        "#loading geodataframe\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "\n",
        "#converting country names to iso codes\n",
        "temp['iso_code'] = coco.convert(names=temp['country'], to ='ISO3')\n",
        "temp = temp[temp['iso_code'] != 'not found']\n",
        "\n",
        "# merging geodataframe and pandas dataframe\n",
        "temp_map = world.merge(temp,left_on = 'iso_a3', right_on = 'iso_code')\n",
        "\n",
        "temp_map.drop(columns = ['continent', 'gdp_md_est','pop_est','name',], inplace = True)\n",
        "temp_map = temp_map.sort_values(by = 'count', ascending = False)\n",
        "\n",
        "\n",
        "#viualization\n",
        "colors = ['#b20710','#ff7f0e','#2ca02c',]\n",
        "cmap  = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors = colors)\n",
        "\n",
        "fig, ax  = plt.subplots(figsize = (15,7.5), dpi = 80)\n",
        "fig.patch.set_facecolor('#FFF8DC')\n",
        "ax.set_facecolor('#FFF8DC')\n",
        "temp_map.dropna().plot(column = 'count',\n",
        "                       color = temp_map.dropna()['color'],\n",
        "                       cmap = cmap,\n",
        "                       scheme='quantiles',\n",
        "                       k=10, legend = False,\n",
        "                       ax = ax)\n",
        "\n",
        "for loc in ['left','right','top','bottom']:\n",
        "    ax.spines[loc].set_visible(False)\n",
        "ax.axes.get_xaxis().set_visible(False)\n",
        "ax.axes.get_yaxis().set_visible(False)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gm67eadjTPNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EVBiYAssVSES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen in this code is a choropleth map. A choropleth map is suitable for this data visualization task for several reasons:\n",
        "\n",
        "1. ***Geographical Context:---*** Choropleth maps are effective for displaying geographical distributions. In this case, the data seems to be related to Netflix show counts in different countries. By mapping the data to a world map, viewers can quickly understand the global distribution of Netflix content.\n",
        "\n",
        "2. ***Data Variation:---*** Choropleth maps use colors to represent data variations across regions. Different shades of colors on the map represent different counts of Netflix content, allowing viewers to identify countries with higher or lower show counts at a glance.\n",
        "\n",
        "3. ***Quick Comparison:---*** With this map, viewers can compare countries side by side in terms of their Netflix content counts. It's easy to identify which countries have a higher count and which have a lower count based on the color intensity.\n",
        "\n",
        "4. ***Geospatial Insights:---*** Choropleth maps provide geospatial insights that can be difficult to convey through other types of charts. For instance, viewers can see patterns of content consumption based on regions, which can lead to interesting observations and insights.\n",
        "\n",
        "5. ***Visual Appeal:---*** The use of colors in choropleth maps makes them visually appealing and engaging. The color choices can also help highlight specific data points or trends.\n",
        "\n",
        "Overall, the choice of the choropleth map is well-suited for visualizing this type of data, as it effectively combines geographical context with data representation, allowing viewers to grasp the distribution of Netflix content counts across different countries."
      ],
      "metadata": {
        "id": "n3yLJ3nCVdeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "5rVsg2f7WTqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can provide some general insights that might be derived from the chart based on the provided code:\n",
        "\n",
        "1. ***Distribution of Netflix Content:---*** The chart allows viewers to understand how the count of Netflix content is distributed across different countries. Countries with a higher count of Netflix content will appear with a darker color, while countries with a lower count will appear with a lighter color.\n",
        "\n",
        "2. ***High-Count Countries:---*** Countries represented with the color **'#b20710'** (likely red) indicate those with a count of Netflix content greater than the 30th value in the dataset. These countries could be potential powerhouses in terms of Netflix content availability.\n",
        "\n",
        "3. ***Medium-Count Countries:---***\n",
        "Countries represented with the color **'#ff7f0e'** likely have a count of Netflix content equal to or less than the 30th value in the dataset. These countries might have a more moderate presence of Netflix content.\n",
        "\n",
        "4. ***Geographical Patterns:---*** Viewers can observe geographical patterns in the distribution of Netflix content. For example, continents or regions with a higher density of red countries might suggest regions with a stronger focus on Netflix content production or consumption.\n",
        "\n",
        "5. ***Outliers:---*** Countries that stand out due to their high or low counts could lead to insights. High outliers might signify countries with unique content offerings, while low outliers might indicate regions with limited access to Netflix content.\n",
        "\n",
        "6. ***Data Variability:---*** The varying color intensities highlight the variability in Netflix content counts across different countries. This can lead to questions about factors influencing this variability, such as cultural preferences, licensing agreements, or market demand.\n",
        "\n",
        "7. ***Regional Comparisons:---*** Viewers can compare neighboring countries or countries within the same region to see how Netflix content counts differ. This can potentially reveal patterns related to regional content preferences.\n",
        "\n",
        "8. ***Data Discrepancies:---*** If a country is unexpectedly colored or doesn't match the expected content count, this might indicate discrepancies in the data or inaccuracies in mapping country names to ISO codes.\n",
        "\n",
        "Remember, these insights are based on the general principles of interpreting choropleth maps. The specific insights you can derive will depend on the actual data being used and the context of the analysis."
      ],
      "metadata": {
        "id": "ocSd4isEWUMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "m0-ICETzXcQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Positive Business Impact:---***\n",
        "\n",
        "1. ***Strategic Content Allocation:---*** High-count regions (red) could be prioritized for content investment, leading to increased viewership and revenue.\n",
        "\n",
        "2. ***Targeted Marketing:---*** Tailoring marketing to regions with high content consumption could boost subscriptions and revenue.\n",
        "\n",
        "3. ***Expansion Opportunities:---*** Gray regions with moderate counts could be targeted for expansion, tapping into new markets.\n",
        "\n",
        "***Negative Growth Potential:---***\n",
        "1. ***Underperforming Regions:---*** Low content counts in high-potential areas might indicate missed growth opportunities.\n",
        "\n",
        "2. ***Market Saturation:---*** High-count regions might be saturated, posing challenges for further growth without innovative strategies.\n",
        "\n",
        "3. ***Regional Preferences:---*** Ignoring regional content preferences could lead to reduced engagement and subscriptions.\n",
        "\n",
        "4. ***Unexplained Outliers:---*** Anomalies or inaccurate data might misguide decisions, potentially causing negative outcomes.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rn4Ppd8OXc9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 19 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = netflix_dataset.corr()\n",
        "\n",
        "# Create a correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Assigning the Ratings into grouped categories\n",
        "ratings = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "netflix_dataset['target_ages'] = netflix_dataset['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "8fKBUOl83t-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type should be a catego\n",
        "netflix_dataset['type'] = pd.Categorical(netflix_dataset['type'])\n",
        "netflix_dataset['target_ages'] = pd.Categorical(netflix_dataset['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])"
      ],
      "metadata": {
        "id": "u-HnynnF3yA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preparing data for heatmap\n",
        "netflix_dataset['count'] = 1\n",
        "data = netflix_dataset.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['country']\n",
        "\n",
        "\n",
        "netflix_dataset_heatmap = netflix_dataset.loc[netflix_dataset['country'].isin(data)]\n",
        "netflix_dataset_heatmap = pd.crosstab(netflix_dataset_heatmap['country'],netflix_dataset_heatmap['target_ages'],normalize = \"index\").T\n",
        "netflix_dataset_heatmap"
      ],
      "metadata": {
        "id": "UUhbymlM3SVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = netflix_dataset_heatmap.corr()\n",
        "\n",
        "# Create a correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2R3G4eIi4fNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The correlation heatmap was chosen because it efficiently visualizes the relationships and strength of correlations between multiple numerical variables in a dataset, helping to identify patterns and dependencies."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The insights from the correlation heatmap include identifying variables with strong positive or negative correlations, helping to understand relationships between different numerical features in the dataset."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 20 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "# Create a pair plot\n",
        "sns.pairplot(netflix_dataset)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot was chosen because it allows for a comprehensive visual exploration of relationships, distributions, and potential correlations among multiple numerical variables in a dataset, aiding in identifying patterns and dependencies."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot reveals insights into the relationships and distributions among pairs of numerical variables, helping to identify potential correlations, trends, and patterns within the dataset."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "\n",
        "Question 1:\n",
        "Is there a statistically significant difference in the average content duration between movies and TV shows?"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Null Hypothesis (H0):---*** There is no difference in audience engagement (IMDb rating) between movies and TV shows.\n",
        "\n",
        "\n",
        "***Alternative Hypothesis (Ha):---*** There is a significant difference in audience engagement (IMDb rating) between movies and TV shows."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Separate data for movies and TV shows\n",
        "movies_duration = netflix_dataset[netflix_dataset['type'] == 'Movie']['duration']\n",
        "tv_shows_duration = netflix_dataset[netflix_dataset['type'] == 'TV Show']['duration']\n",
        "\n",
        "# Perform an independent t-test\n",
        "t_stat, p_value = stats.ttest_ind(movies_duration, tv_shows_duration, equal_var=False)\n",
        "\n",
        "print(\"P-value :\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-value is the independent two-sample t-test."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I chose the independent two-sample t-test because it's suitable for comparing the means of two independent groups (movies and TV shows) and determining if the observed difference in content duration is statistically significant.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "Question 2:\n",
        "Does the release year of content significantly influence its IMDb rating?"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "***Null Hypothesis (H0):---*** There is no association between the content type and its content rating. The distribution of content ratings is independent of the content type.\n",
        "\n",
        "\n",
        "***Alternative Hypothesis (Ha):---*** There is a significant association between the content type and its content rating. The distribution of content ratings is dependent on the content type."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create a contingency table of content type and content rating\n",
        "contingency_table = pd.crosstab(netflix_dataset['type'], netflix_dataset['rating'])\n",
        "\n",
        "# Perform the chi-square test\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"P-value for Content Type and Content Rating:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test I used to obtain the p-value for analyzing the association between content type ('type') and content rating ('rating') is the chi-square test of independence."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I chose the chi-square test of independence because it's suitable for analyzing the association between two categorical variables, such as content type (movie/TV show) and content rating (categorical levels). This test helps determine whether there's a significant relationship or association between these two categorical variables. The chi-square test is commonly used for situations where you want to assess whether the observed distribution of data differs significantly from what you would expect under the assumption of independence."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "Question 3  --- Is there a significant association between the content type (movie/TV show) and the country of origin?"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Null Hypothesis (H0):---*** There is no association between the content type and the country of origin. The distribution of content types is independent of the countries.\n",
        "\n",
        "\n",
        "\n",
        "***Alternative Hypothesis (Ha):---*** There is a significant association between the content type and the country of origin. The distribution of content types is dependent on the countries."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create a contingency table of content type and content country\n",
        "contingency_table = pd.crosstab(netflix_dataset['type'], netflix_dataset['country'])\n",
        "\n",
        "# Perform the chi-square test\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"P-value for Content Type and Content Country:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The statistical test I used to obtain the p-value for analyzing the association between content type ('type') and content country ('country') is the chi-square test of independence."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I chose the chi-square test of independence because it's suitable for analyzing the association between two categorical variables, such as content type (movie/TV show) and content country (categorical levels). This test helps determine whether there's a significant relationship or association between these two categorical variables. The chi-square test is commonly used for situations where you want to assess whether the observed distribution of data differs significantly from what you would expect under the assumption of independence. In this case, it will help us understand if there's a significant association between the content type and the country of origin."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check for missing values\n",
        "missing_values = netflix_dataset.isnull().sum()\n",
        "print(\"Missing Values:\\n\", missing_values)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " There are no missing values indicated in the output. Since all columns have a count of 0 for missing values, there is no need to apply missing value imputation techniques. Therefore, the code does not include any missing value imputation techniques.\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Select numeric columns to check for outliers\n",
        "numeric_columns = ['release_year', 'duration']\n",
        "\n",
        "# Create box plots for each numeric column\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=netflix_dataset[numeric_columns])\n",
        "plt.title('Box Plot for Numeric Columns')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert columns to numeric\n",
        "netflix_dataset[numeric_columns] = netflix_dataset[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handling outliers\n",
        "for column in numeric_columns:\n",
        "  q1 = netflix_dataset[column].quantile(0.25)\n",
        "  q3 = netflix_dataset[column].quantile(0.75)\n",
        "  iqr = q3 - q1\n",
        "  lower_bound = q1 -  1.5 * iqr\n",
        "  upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "  # Replace outliers with NaN or limit  them to lower/upper bounds\n",
        "  netflix_dataset[column] = np.where(\n",
        "      (netflix_dataset[column] < lower_bound) | (netflix_dataset[column] > upper_bound),\n",
        "      np.nan,\n",
        "      netflix_dataset[column]\n",
        "  )\n"
      ],
      "metadata": {
        "id": "PmbY0rNF85dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values in columns after handling outliers\n",
        "netflix_dataset.fillna(netflix_dataset.median(), inplace=True)\n",
        "\n",
        "# Create box plot after outlier treatment\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(data=netflix_dataset[numeric_columns])\n",
        "plt.title(\"Box plot for  numeric columns after outliers treatment\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xg3Qh7BH-gfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Interquartile Range (IQR) method to identify and handle outliers in the provided code. I chose this technique for its robustness to extreme values, non-parametric nature, and compatibility with skewed distributions. The IQR method focuses on the middle 50% of the data, making it suitable for datasets with potential outliers that could distort summary statistics."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Replace 'TV Show' with 0 and 'Movie' with 1 in the 'type' column\n",
        "netflix_dataset['type'].replace({'TV Show': 0, 'Movie': 1}, inplace=True)\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove special characters from the 'title' column\n",
        "netflix_dataset['title'] = netflix_dataset['title'].str.replace(r'[^\\w\\s]', '')\n"
      ],
      "metadata": {
        "id": "9rVoF1qtIcLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert month_added and year_added columns to datetime format\n",
        "netflix_dataset['month_added'] = pd.to_datetime(netflix_dataset['month_added'])\n",
        "netflix_dataset['year_added'] = pd.to_datetime(netflix_dataset['year_added'])\n",
        "\n",
        "# Format the columns as \"dd-mm-yyyy\"\n",
        "netflix_dataset['month_added'] = netflix_dataset['month_added'].dt.strftime('%d-%m-%Y')\n",
        "netflix_dataset['year_added'] = netflix_dataset['year_added'].dt.strftime('%d-%m-%Y')\n"
      ],
      "metadata": {
        "id": "Hp6t7XvwJk37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'duration' and 'release_year' columns to integer\n",
        "netflix_dataset['duration'] = netflix_dataset['duration'].astype(int)\n",
        "netflix_dataset['release_year'] = netflix_dataset['release_year'].astype(int)\n"
      ],
      "metadata": {
        "id": "U1Dt5ucBKVuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I done some changes in rating coulmn:----\n",
        "\n",
        "\n",
        "***Kids :--- ***\n",
        "\n",
        "'TV-Y':------ 'Kids'---- 0\n",
        "\n",
        "'TV-G':------ 'Kids' ---- 0\n",
        "\n",
        "'G':--------- 'Kids'---- 0\n",
        "\n",
        "***'Older Kids' ----***\n",
        "\n",
        "'TV-PG':------- 'Older Kids' ---- 1\n",
        "\n",
        "'TV-Y7-FV':---- 'Older Kids' ---- 1\n",
        "\n",
        "'TV-Y7':------- 'Older Kids'----1\n",
        "\n",
        "'PG': --------- 'Older Kids'------ 1\n",
        "\n",
        "*** 'Teens' -----***\n",
        "\n",
        "'TV-14':------- 'Teens' ---- 2\n",
        "\n",
        "'PG-13': ------ 'Teens' ----- 2\n",
        "\n",
        "*** 'Adults'---- ***\n",
        "\n",
        "'TV-MA':------- 'Adults' ---- 3\n",
        "\n",
        "'R':----------- 'Adults'----3\n",
        "\n",
        "'NR':---------- 'Adults' ----- 3\n",
        "    \n",
        "'UR':---------- 'Adults' ------ 3\n",
        "\n",
        "'NC-17':------- 'Adults' ----- 3"
      ],
      "metadata": {
        "id": "j5HryUSTMflZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the values in the 'rating' column\n",
        "netflix_dataset['rating'] = netflix_dataset['rating'].replace({\n",
        "    'TV-Y': 0,\n",
        "    'TV-Y7': 1,\n",
        "    'TV-Y7-FV': 1,\n",
        "    'TV-G': 0,\n",
        "    'TV-PG': 1,\n",
        "    'TV-14': 2,\n",
        "    'TV-MA': 3,\n",
        "    'G': 0,\n",
        "    'PG': 1,\n",
        "    'PG-13': 2,\n",
        "    'R': 3,\n",
        "    'NC-17': 3,\n",
        "    'NR': 3,\n",
        "    'UR': 3\n",
        "})\n"
      ],
      "metadata": {
        "id": "tbEWTFEwMG15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Iterate through the DataFrame\n",
        "# Iterate through the DataFrame\n",
        "for index, row in netflix_dataset.iterrows():\n",
        "    show_id = row['show_id']\n",
        "    numeric_part = show_id[1:]\n",
        "    new_show_id = f\"0{numeric_part}\"\n",
        "    netflix_dataset.at[index, 'show_id'] = int(new_show_id)"
      ],
      "metadata": {
        "id": "h0agYXy3flQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the updated dataset\n",
        "print(netflix_dataset.head())"
      ],
      "metadata": {
        "id": "_l8uyrShKgqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the following categorical encoding techniques and the reasons for using them are as follows:---\n",
        "\n",
        "1. ***Label Encoding---*** I used label encoding to convert the 'type' column ('TV Show' and 'Movie') into numerical values (0 and 1) because there is an inherent ordinal relationship between these categories: 'TV Show' can be considered as 0 and 'Movie' as 1.\n",
        "\n",
        "2. ***One-Hot Encoding:---*** I used one-hot encoding for the 'target_ages' column since it represents nominal categories ('Kids', 'Older Kids', 'Teens', 'Adults'). One-hot encoding creates separate binary columns for each category, preserving their individual relationships without imposing any ordinality.\n",
        "\n",
        "3. ***Custom Encoding:---*** For the 'rating' column, I used a custom mapping to encode the ratings into numerical values (0 to 3), where 'TV-Y' is encoded as 0, 'TV-Y7' and 'TV-Y7-FV' as 1, 'TV-G' as 0, 'TV-PG' as 1, 'TV-14' as 2, 'TV-MA' as 3, 'G' as 0, 'PG' as 1, 'PG-13' as 2, 'R', 'NC-17', 'NR', and 'UR' as 3. This custom encoding captures the hierarchical nature of content ratings.\n",
        "\n",
        "4. ***Feature Engineering:---*** I extracted the 'month_added' and 'year_added' columns to represent the month and year as separate features. This allows the model to capture potential temporal patterns that may influence user engagement.\n",
        "\n",
        "The choice of encoding techniques depends on the nature of the data, the relationships between categories, and the requirements of the analysis or machine learning model. It's essential to consider the context and potential impact of encoding on the analysis or model's performance."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "# Function to expand contractions\n",
        "def expand_contractions(text, contractions_dict):\n",
        "    words = text.split()\n",
        "    expanded_words = [contractions_dict.get(word, word) for word in words]\n",
        "    expanded_text = ' '.join(expanded_words)\n",
        "    return expanded_text\n",
        "\n",
        "# Function to expand contractions in a column\n",
        "def expand_contractions_column(column, contractions_dict):\n",
        "    expanded_column = column.apply(lambda text: expand_contractions(text, contractions_dict))\n",
        "    return expanded_column\n",
        "\n",
        "\n",
        "# Define a dictionary of common contractions and their expansions\n",
        "contractions_dict = {\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    # ... (add more contractions)\n",
        "}\n",
        "\n",
        "# Expand contractions in the 'description' column, for example\n",
        "netflix_dataset['description'] = expand_contractions_column(netflix_dataset['description'], contractions_dict)\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase the 'description' column\n",
        "netflix_dataset['description'] = netflix_dataset['description'].str.lower()"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuations from the 'description' column\n",
        "punctuations = string.punctuation\n",
        "netflix_dataset['description'] = netflix_dataset['description'].apply(lambda text: ''.join([char for char in text if char not in punctuations]))\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "# Remove URLs from the 'description' column\n",
        "netflix_dataset['description'] = netflix_dataset['description'].apply(lambda text: re.sub(r'http\\S+', '', text))\n",
        "\n",
        "# Remove words containing digits from the 'description' column\n",
        "netflix_dataset['description'] = netflix_dataset['description'].apply(lambda text: ' '.join([word for word in text.split() if not any(char.isdigit() for char in word)]))"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "# Download the stopwords list if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Get the list of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the remove_stopwords function to the 'description' column\n",
        "netflix_dataset['description'] = netflix_dataset['description'].apply(remove_stopwords)\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove white spaces from the 'description' column\n",
        "netflix_dataset['description'] = netflix_dataset['description'].str.replace('\\s+', ' ', regex=True)"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "# Function to rephrase a sentence by randomly replacing words\n",
        "def rephrase_sentence(sentence):\n",
        "    words = sentence.split()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if len(word) > 3 and random.random() < 0.3:  # Replace words with probability 0.3\n",
        "            new_words.append('variation')\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# Rephrase descriptions and replace them in the dataset\n",
        "rephrased_descriptions = []\n",
        "\n",
        "for description in netflix_dataset['description']:\n",
        "    rephrased = rephrase_sentence(description)\n",
        "    rephrased_descriptions.append(rephrased)\n",
        "\n",
        "netflix_dataset['rephrased_description'] = rephrased_descriptions"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the 'description' column\n",
        "# Download the necessary resource\n",
        "nltk.download('punkt')\n",
        "# Tokenize the 'description' column\n",
        "netflix_dataset['tokenized_description'] = netflix_dataset['description'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "# Function to perform text normalization\n",
        "def normalize_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove punctuation and stopwords\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words('english')]\n",
        "\n",
        "    # Perform stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # Join tokens back into a normalized text\n",
        "    normalized_text = ' '.join(stemmed_tokens)\n",
        "    return normalized_text\n",
        "\n",
        "# Apply text normalization to 'description' column\n",
        "netflix_dataset['normalized_description'] = netflix_dataset['description'].apply(normalize_text)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the following text normalization techniques:----\n",
        "1. ***Lowercasing:---*** Converting all text to lowercase. This is commonly done to ensure uniformity and to treat uppercase and lowercase versions of the same word as identical.\n",
        "\n",
        "2. ***Tokenization:---*** Splitting text into individual words or tokens. Tokenization helps break down the text into meaningful units, which is essential for further text processing.\n",
        "\n",
        "3. ***Punctuation Removal:---*** Removing punctuation marks from the text. Punctuation marks often don't contribute much to the meaning of the text and can be safely removed.\n",
        "\n",
        "4. ***Stopword Removal:---*** Removing common words like \"the,\" \"and,\" \"is,\" etc., which don't carry significant meaning and can be safely discarded.\n",
        "\n",
        "5. ***Stemming:---*** Reducing words to their base or root form. This helps to group together words with the same root, which can be useful for text analysis.\n",
        "\n",
        "I used these techniques because they are fundamental steps in text normalization. Lowercasing ensures consistency in word representations, tokenization breaks down text into manageable units, punctuation and stopwords removal reduce noise, and stemming helps with word grouping. These techniques collectively improve the quality and consistency of the text data, making it more suitable for various text analysis tasks such as text classification, sentiment analysis, and more."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Function to perform POS tagging\n",
        "def pos_tagging(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    return pos_tags\n",
        "\n",
        "# Apply POS tagging to 'description' column\n",
        "netflix_dataset['pos_tags'] = netflix_dataset['description'].apply(pos_tagging)"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features as needed\n",
        "\n",
        "# Fit and transform the 'description' column using the vectorizer\n",
        "tfidf_matrix = vectorizer.fit_transform(netflix_dataset['description'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I provided an example code for using the Term Frequency-Inverse Document Frequency (TF-IDF) vectorization technique. TF-IDF is widely used for capturing word importance in documents and is effective for tasks like text classification and clustering."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = netflix_dataset.corr()\n",
        "\n",
        "# Displat  highly correlated  features (thresholf can be adjusted)\n",
        "highly_correlated = (correlation_matrix >  0.8) & (correlation_matrix < 1.0)\n",
        "print(\"Highly correlated features:\")\n",
        "print(correlation_matrix[highly_correlated])\n",
        "\n",
        "# Drop highly correlated features (example: 'release_year' and 'year_added')\n",
        "netflix_dataset.drop(columns=['year_added'], inplace=True)\n",
        "\n",
        "# Create a new feature by combining existing features (example: 'duration' + 'release_year')\n",
        "netflix_dataset['duration_year_combo'] = netflix_dataset['duration'] + netflix_dataset['release_year']\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = netflix_dataset.corr()\n",
        "\n",
        "# Display the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Identify highly correlated features\n",
        "threshold = 0.7  # Define your threshold for correlation\n",
        "highly_correlated = []\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        if abs(correlation_matrix.iloc[i, j]) >= threshold:\n",
        "            pair = (correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
        "            highly_correlated.append(pair)\n",
        "\n",
        "print(\"Highly Correlated Features:\")\n",
        "for feature1, feature2 in highly_correlated:\n",
        "    print(f\"{feature1} and {feature2} - Correlation: {correlation_matrix.loc[feature1, feature2]}\")"
      ],
      "metadata": {
        "id": "x0PXjXTddq2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No need  for feature selection"
      ],
      "metadata": {
        "id": "truHFEfZOl5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# List of categorical and numeric columns\n",
        "categorical_columns = [ 'country', 'target_ages']\n",
        "numeric_columns = ['type','release_year', 'duration', 'count']\n",
        "\n",
        "# Define the transformations for each column type\n",
        "transformers = [\n",
        "    ('categorical', OneHotEncoder(), categorical_columns),\n",
        "    ('numeric', MinMaxScaler(), numeric_columns)\n",
        "]\n",
        "\n",
        "# Create a ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers)\n",
        "\n",
        "# Fit and transform the data\n",
        "transformed_data = preprocessor.fit_transform(netflix_dataset)"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# List of numeric columns to be scaled\n",
        "numeric_columns = ['type','release_year', 'duration', 'count']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Apply Min-Max Scaling to the numeric columns\n",
        "netflix_dataset[numeric_columns] = scaler.fit_transform(netflix_dataset[numeric_columns])"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Min-Max Scaling method to scale the data. Min-Max Scaling transforms the data to a specific range (usually between 0 and 1), preserving the relative relationships between data points. It's particularly useful when the features have different scales and we want to bring them to a common scale for modeling purposes. This helps in preventing features with larger scales from dominating the model and ensures that all features contribute equally to the analysis."
      ],
      "metadata": {
        "id": "wNdu2uK0opqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "# No need"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}